{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T12:57:52.431407Z",
     "start_time": "2020-09-19T12:57:52.114637Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging as log\n",
    "import urllib\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Add source folder\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "sys.path.append(os.path.abspath(\"../src/processing/local-geocode\"))\n",
    "\n",
    "# Load constants\n",
    "from src.constants import DATA_PATH, LOCATION_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Download geonames data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T11:28:16.308736Z",
     "start_time": "2020-09-19T11:27:57.159904Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# download file\n",
    "url = 'https://download.geonames.org/export/dump/allCountries.zip'\n",
    "log.info(f'Downloading data from {url}')\n",
    "geonames_data_path_zip = os.path.join(LOCATION_PATH, \"geonames_data_allCountries.zip\")\n",
    "urllib.request.urlretrieve(url, geonames_data_path_zip)\n",
    "log.info(f'... done')\n",
    "log.info('Extracting data...')\n",
    "# extract\n",
    "with zipfile.ZipFile(geonames_data_path_zip, 'r') as f:\n",
    "    f.extractall(LOCATION_PATH)\n",
    "log.info('...done')\n",
    "# remove zip file\n",
    "#os.remove(geonames_data_path_zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T11:36:34.244635Z",
     "start_time": "2020-09-19T11:36:06.797270Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dtypes = {'name': str, 'latitude': float, 'longitude': float, 'country_code': str, 'population': int, 'feature_code': str, 'alternatenames': str,  \"feature_class\": str, \"asciiname\": str, \"admin1\":str, \"cc2\": str}\n",
    "geonames_columns = ['geonameid', 'name', 'asciiname', 'alternatenames', 'latitude', 'longitude', 'feature_class', 'feature_code', 'country_code', 'cc2', 'admin1', 'admin2', 'admin3', 'admin4', 'population', 'elevation', 'dem', 'timezone', 'modification_date']\n",
    "\n",
    "geonames_data_path = os.path.join(LOCATION_PATH, \"allCountries.txt\")\n",
    "df = pd.read_csv(geonames_data_path, names=geonames_columns, sep='\\t', dtype=dtypes, usecols=dtypes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T11:39:00.319514Z",
     "start_time": "2020-09-19T11:38:30.575552Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "joblib.dump(df, os.path.join(LOCATION_PATH, \"all_locations.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Using Geocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T11:27:30.247066Z",
     "start_time": "2020-09-19T11:27:21.810836Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from geocode.geocode import Geocode\n",
    "\n",
    "geocoder = Geocode()\n",
    "geocoder.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## single cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T11:29:06.462148Z",
     "start_time": "2020-09-19T11:29:06.456739Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geocoder.decode(\"Ich war heute in zurich und habe eine Pizza gegessen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## multi cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T10:44:28.446947Z",
     "start_time": "2020-09-19T10:44:15.085017Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locations = [\"zurich\", \"basel\", \"sarnen\", \"giswil\", \"goldach\", \"gruet\", \"bregenz\"]\n",
    "geocoder.decode_parallel(locations, num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T10:40:24.439691Z",
     "start_time": "2020-09-19T10:40:12.880710Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "geonames = joblib.load(\"/tmp/local_geocode/geonames.pkl\")\n",
    "\n",
    "places_in_switzerland = []\n",
    "for place in geonames:\n",
    "    if place[1] == \"CH\":\n",
    "        places_in_switzerland.append(place)\n",
    "\n",
    "swiss_places = {entry[0] : tuple(entry[1:]) for entry in places_in_switzerland}\n",
    "global_places = {entry[0] : tuple(entry[1:]) for entry in geonames}\n",
    "\n",
    "# Save\n",
    "#joblib.dump(swiss_places, \"/mnt/data/location_data/swiss_places.pkl\")\n",
    "#joblib.dump(global_places, \"/mnt/data/location_data/global_places.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Hierarchical processing of places in Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T12:58:15.127296Z",
     "start_time": "2020-09-19T12:57:54.422363Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = joblib.load(os.path.join(LOCATION_PATH, \"archive\", \"all_locations.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Filter locations for countries, towns and admin areas and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T12:59:07.396573Z",
     "start_time": "2020-09-19T12:58:52.350010Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "population_thres = 200\n",
    "\n",
    "def is_ascii(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "log.info('Transforming geonames data...')\n",
    "log.info('Reading geo data...')\n",
    "# select places with a population greater zero\n",
    "df = df[(df.population > population_thres) | (df.feature_code == 'PCLI')]\n",
    "# get rid of administrative zones without country codes (e.g. \"The Commonwealth\")\n",
    "df = df[~df.country_code.isnull()]\n",
    "# select places with feature class A (admin) and P (place)\n",
    "df = df[df.feature_class.isin(['A', 'P'])]\n",
    "# expand alternate names\n",
    "df.loc[:, 'alternatenames'] = df.alternatenames.str.split(',')\n",
    "df['is_altname'] = False\n",
    "_df = df.explode('alternatenames')\n",
    "_df['name'] = _df['alternatenames']\n",
    "_df['is_altname'] = True\n",
    "df = pd.concat([df, _df])\n",
    "# Remove all names that are floats/ints\n",
    "df['is_str'] = df.name.apply(lambda s: isinstance(s, str))\n",
    "df = df[df['is_str']]\n",
    "# Levels of priority:\n",
    "# 1) Prioritize large cities (population size > large_city_population_cutoff)\n",
    "# 2) Admin areas\n",
    "# 3) Places\n",
    "# Within each group we will sort according to population size\n",
    "log.info('Sorting by priority...')\n",
    "feature_code_priorities = ['A', 'P']\n",
    "feature_code_priorities = {k: i+1 for i, k in enumerate(feature_code_priorities)}\n",
    "df['priority'] = df.feature_class.apply(lambda code: feature_code_priorities[code])\n",
    "# Only allow 2 character names in specific cases\n",
    "# - Name is non-ascii (e.g. Chinese characters)\n",
    "# - Is an alternative name for a country (e.g. UK)\n",
    "# - Is a US state or Canadian province\n",
    "df['is_ascii'] = df.name.apply(is_ascii)\n",
    "df['is_country'] = df.feature_code.str.startswith('PCL')\n",
    "df = df[\n",
    "        (~df.is_ascii) | \n",
    "        (df.name.str.len() > 2) | \n",
    "        ((df.name.str.len() == 2) & (df.country_code == 'US')) |\n",
    "        ((df.name.str.len() == 2) & (df.country_code == 'CA')) |\n",
    "        ((df.name.str.len() == 2) & (df.is_country))\n",
    "        ]\n",
    "# add \"US\" manually since it's missing in geonames\n",
    "row_usa = df[df.is_country & (df.name == 'USA')].iloc[0]\n",
    "row_usa['name'] = 'US'\n",
    "df = df.append(row_usa)\n",
    "# sort by priorities and drop name duplicates (this way we will keep only the high priority elements)\n",
    "df.sort_values(by=['priority', 'population'], ascending=[True, False], inplace=True)\n",
    "df['name_lower'] = df.name.str.lower()\n",
    "df = df.drop_duplicates('name_lower', keep='first')\n",
    "log.info(f'... collected a total of {len(df):,} names of places and countries')\n",
    "\n",
    "\n",
    "# Save filtered data\n",
    "#joblib.dump(swiss_data, os.path.join(LOCATION_PATH, \"global_location_df.pkl\"))\n",
    "#joblib.dump(df, os.path.join(LOCATION_PATH, \"global_location_df.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Extra priority granularity in Switzerland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T13:13:33.690208Z",
     "start_time": "2020-09-19T13:13:33.673415Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Design extra priorities within Switzerland\n",
    "swiss_data = df[df['country_code'] == 'CH']\n",
    "\n",
    "# 1. Extract swiss country lvl location data\n",
    "swiss_country = swiss_data[swiss_data.is_country]\n",
    "\n",
    "# 2. Extract swiss admin areas\n",
    "swiss_administrative_areas = swiss_data[\n",
    "    (swiss_data[\"feature_class\"] == \"A\") & \n",
    "    (swiss_data.is_country == False)\n",
    "]\n",
    "swiss_administrative_areas = swiss_administrative_areas.sort_values(by=\"population\", inplace=False)\n",
    "\n",
    "# 3. Extract swiss towns\n",
    "swiss_towns = swiss_data[swiss_data[\"feature_class\"] == \"P\"]\n",
    "\n",
    "# Combine in list\n",
    "location_dfs = [swiss_country_lvl, swiss_administrative_areas, swiss_towns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T13:21:44.654554Z",
     "start_time": "2020-09-19T13:21:43.360155Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Turn data into dictionaries that can be used with keywordsearch\n",
    "swiss_country = {}\n",
    "swiss_admin_areas = {}\n",
    "swiss_towns = {}\n",
    "\n",
    "swiss_dicts = [swiss_country, swiss_admin_areas, swiss_towns]\n",
    "\n",
    "for loc_dict, loc_df in zip(swiss_dicts, location_dfs):\n",
    "    \n",
    "    for idx, row in loc_df.iterrows():\n",
    "        loc_dict[row[\"name\"]] = (row.latitude, row.longitude, row.admin1, row.population, row.feature_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-19T13:24:39.778020Z",
     "start_time": "2020-09-19T13:24:39.545139Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/data/location_data/swiss_towns_dict.pkl']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save\n",
    "joblib.dump(swiss_country, os.path.join(LOCATION_PATH, \"swiss_country_dict.pkl\"))\n",
    "joblib.dump(swiss_admin_areas, os.path.join(LOCATION_PATH, \"swiss_adminareas_dict.pkl\"))\n",
    "joblib.dump(swiss_towns, os.path.join(LOCATION_PATH, \"swiss_towns_dict.pkl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Get list of all places in Switzerland (old)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
